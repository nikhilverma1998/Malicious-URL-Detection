{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T15:47:40.915706Z",
     "iopub.status.busy": "2023-03-30T15:47:40.915298Z",
     "iopub.status.idle": "2023-03-30T15:47:42.812786Z",
     "shell.execute_reply": "2023-03-30T15:47:42.811830Z",
     "shell.execute_reply.started": "2023-03-30T15:47:40.915626Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T15:47:42.815514Z",
     "iopub.status.busy": "2023-03-30T15:47:42.815057Z",
     "iopub.status.idle": "2023-03-30T15:47:44.129442Z",
     "shell.execute_reply": "2023-03-30T15:47:44.128427Z",
     "shell.execute_reply.started": "2023-03-30T15:47:42.815486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>br-icloud.com.br</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mp3raid.com/music/krizz_kaliko.html</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bopsecrets.org/rexroth/cr/1.htm</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.garage-pirenne.be/index.php?option=...</td>\n",
       "      <td>defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://adventure-nicaragua.net/index.php?optio...</td>\n",
       "      <td>defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651186</th>\n",
       "      <td>xbox360.ign.com/objects/850/850402.html</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651187</th>\n",
       "      <td>games.teamxbox.com/xbox-360/1860/Dead-Space/</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651188</th>\n",
       "      <td>www.gamespot.com/xbox360/action/deadspace/</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651189</th>\n",
       "      <td>en.wikipedia.org/wiki/Dead_Space_(video_game)</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651190</th>\n",
       "      <td>www.angelfire.com/goth/devilmaycrytonite/</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>651191 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url        type\n",
       "0                                        br-icloud.com.br    phishing\n",
       "1                     mp3raid.com/music/krizz_kaliko.html      benign\n",
       "2                         bopsecrets.org/rexroth/cr/1.htm      benign\n",
       "3       http://www.garage-pirenne.be/index.php?option=...  defacement\n",
       "4       http://adventure-nicaragua.net/index.php?optio...  defacement\n",
       "...                                                   ...         ...\n",
       "651186            xbox360.ign.com/objects/850/850402.html    phishing\n",
       "651187       games.teamxbox.com/xbox-360/1860/Dead-Space/    phishing\n",
       "651188         www.gamespot.com/xbox360/action/deadspace/    phishing\n",
       "651189      en.wikipedia.org/wiki/Dead_Space_(video_game)    phishing\n",
       "651190          www.angelfire.com/goth/devilmaycrytonite/    phishing\n",
       "\n",
       "[651191 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../input/malicious-urls-dataset/malicious_phish.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class and functions to get label from index and index from label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T15:47:44.131231Z",
     "iopub.status.busy": "2023-03-30T15:47:44.130762Z",
     "iopub.status.idle": "2023-03-30T15:47:44.191537Z",
     "shell.execute_reply": "2023-03-30T15:47:44.190509Z",
     "shell.execute_reply.started": "2023-03-30T15:47:44.131195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Label_Index:\n",
    "    def __init__(self, dataset):\n",
    "        self.labels = dataset['type'].unique()\n",
    "        self.label_index = {label: index for index, label in enumerate(self.labels)}\n",
    "        self.index_label = {index: label for index, label in enumerate(self.labels)}\n",
    "    \n",
    "    def indexes_labels(self, dataset):\n",
    "        return dataset['type'].map(self.index_label)\n",
    "\n",
    "    def labels_indexes(self, dataset):\n",
    "        return dataset['type'].map(self.label_index)\n",
    "    def __call__(self, label):\n",
    "        return self.label_index[label]\n",
    "\n",
    "label_index = Label_Index(dataset)\n",
    "label_index('phishing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T15:47:44.195069Z",
     "iopub.status.busy": "2023-03-30T15:47:44.194708Z",
     "iopub.status.idle": "2023-03-30T15:47:47.440689Z",
     "shell.execute_reply": "2023-03-30T15:47:47.439448Z",
     "shell.execute_reply.started": "2023-03-30T15:47:44.195031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 4, 6, 10, 9, 0, 1], 333)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Char_Index:\n",
    "    def __init__(self, urls) -> None:\n",
    "        self.char_index = {}\n",
    "        self.index_char = {}\n",
    "        for url in urls:\n",
    "            for char in url:\n",
    "                if char not in self.char_index:\n",
    "                    self.char_index[char] = len(self.char_index)\n",
    "                    self.index_char[len(self.index_char)] = char\n",
    "    \n",
    "    def string_indexes(self, string):\n",
    "        return [self.char_index[char] for char in string]\n",
    "\n",
    "char_index = Char_Index(dataset['url'])\n",
    "char_index.string_indexes(dataset.url[0]), len(char_index.char_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data into train and test in ratio of 80:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T15:47:47.446363Z",
     "iopub.status.busy": "2023-03-30T15:47:47.445406Z",
     "iopub.status.idle": "2023-03-30T15:47:47.650664Z",
     "shell.execute_reply": "2023-03-30T15:47:47.649363Z",
     "shell.execute_reply.started": "2023-03-30T15:47:47.446313Z"
    }
   },
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_data = dataset[:int(len(dataset)*0.8)]\n",
    "test_data = dataset[int(len(dataset)*0.8):].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T15:47:47.656469Z",
     "iopub.status.busy": "2023-03-30T15:47:47.655685Z",
     "iopub.status.idle": "2023-03-30T15:47:47.673521Z",
     "shell.execute_reply": "2023-03-30T15:47:47.672525Z",
     "shell.execute_reply.started": "2023-03-30T15:47:47.656428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(520952, 130239)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, char_index: Char_Index, label_index: Label_Index) -> None:\n",
    "        self.df = df\n",
    "        self.char_index = char_index\n",
    "        self.label_index = label_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        url = self.df.url[index]\n",
    "        label = self.label_index(self.df.type[index])\n",
    "        return torch.tensor(self.char_index.string_indexes(url)), torch.tensor(label)\n",
    "\n",
    "trainDataset = Dataset(train_data, char_index, label_index)\n",
    "testDataset = Dataset(test_data, char_index, label_index)\n",
    "len(trainDataset), len(testDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to pad the tensors to make them equal length and generate batch for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T15:47:47.678997Z",
     "iopub.status.busy": "2023-03-30T15:47:47.678007Z",
     "iopub.status.idle": "2023-03-30T15:47:47.927655Z",
     "shell.execute_reply": "2023-03-30T15:47:47.926404Z",
     "shell.execute_reply.started": "2023-03-30T15:47:47.678956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[13, 22,  1,  ...,  0,  0,  0],\n",
      "        [26, 26, 26,  ...,  0,  0,  0],\n",
      "        [66, 13, 15,  ...,  0,  0,  0],\n",
      "        ...,\n",
      "        [ 0, 13, 27,  ...,  0,  0,  0],\n",
      "        [ 0,  3,  6,  ...,  0,  0,  0],\n",
      "        [19, 20, 20,  ...,  0,  0,  0]]) tensor([1, 0, 1, 1, 2, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 2, 0, 1, 1, 1, 0, 2, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
      "        2, 2, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 2, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 3, 2, 1, 1, 2,\n",
      "        0, 2, 0, 0, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 2, 1, 0,\n",
      "        2, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 3, 1, 1, 1, 1, 0, 2, 2, 1, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 0, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
      "        2, 1, 1, 3, 1, 0, 0, 3, 0, 0, 1, 0, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1,\n",
      "        1, 2, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch):\n",
    "    urls, labels = zip(*batch)\n",
    "    urls = nn.utils.rnn.pad_sequence(urls, batch_first=True)\n",
    "    return urls, torch.tensor(labels)\n",
    "\n",
    "trainGenerator = torch.utils.data.DataLoader(trainDataset, batch_size=256, shuffle=True, collate_fn=collate_fn, num_workers = 2)\n",
    "testGenerator = torch.utils.data.DataLoader(testDataset, batch_size=256, shuffle=True, collate_fn=collate_fn, num_workers = 2)\n",
    "for inputs, labels in trainGenerator:\n",
    "    print(inputs, labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T15:47:47.936542Z",
     "iopub.status.busy": "2023-03-30T15:47:47.932321Z",
     "iopub.status.idle": "2023-03-30T15:47:47.945452Z",
     "shell.execute_reply": "2023-03-30T15:47:47.943179Z",
     "shell.execute_reply.started": "2023-03-30T15:47:47.936497Z"
    }
   },
   "outputs": [],
   "source": [
    "teststr = \"https://web.whatsapp.com/\"\n",
    "#teststr = Char_Index(dataset['url'])\n",
    "#teststr.string_indexes(\"www.web.whatsapp.com\"), len(teststr.char_index)\n",
    "predictDataset = Dataset(teststr, char_index, label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T15:47:47.949091Z",
     "iopub.status.busy": "2023-03-30T15:47:47.947960Z",
     "iopub.status.idle": "2023-03-30T15:47:47.960595Z",
     "shell.execute_reply": "2023-03-30T15:47:47.959028Z",
     "shell.execute_reply.started": "2023-03-30T15:47:47.949049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implementation of GRU and forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T15:47:47.969557Z",
     "iopub.status.busy": "2023-03-30T15:47:47.967250Z",
     "iopub.status.idle": "2023-03-30T15:47:49.542118Z",
     "shell.execute_reply": "2023-03-30T15:47:49.541105Z",
     "shell.execute_reply.started": "2023-03-30T15:47:47.969522Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2747, -0.1274,  0.3276,  0.0098],\n",
       "        [ 0.1230, -0.0037,  0.1447,  0.2633],\n",
       "        [-0.1264, -0.2434,  0.1468, -0.0941],\n",
       "        ...,\n",
       "        [-0.1006, -0.1365,  0.0906, -0.0488],\n",
       "        [ 0.1369, -0.1260,  0.0284, -0.0267],\n",
       "        [-0.2293,  0.1638,  0.2110,  0.2513]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, output_size, num_layers=1, dropout=0.2, bidirectional=False):\n",
    "        super(GRU, self).__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size, num_layers, dropout=dropout, batch_first=True, bidirectional=bidirectional)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)   # [batch_size, seq_len] -> [batch_size, seq_len, embedding_size]\n",
    "        if self.bidirectional == True:\n",
    "            h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(x.device)   # [num_layers*2, batch_size, hidden_size]\n",
    "        else:\n",
    "            h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)  # [num_layers, batch_size, hidden_size]\n",
    "        out, _ = self.gru(x, h0)    # [batch_size, seq_len, hidden_size]\n",
    "        if self.bidirectional == True:\n",
    "            out = out[:, -1, :self.hidden_size] + out[:, 0, self.hidden_size:]  # [batch_size, hidden_size]\n",
    "        return self.fc(out)\n",
    "gru_model = GRU(len(char_index.char_index), 128, 128, len(label_index.labels), bidirectional=True, num_layers=1)\n",
    "gru_model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T15:48:17.473169Z",
     "iopub.status.busy": "2023-03-30T15:48:17.472635Z",
     "iopub.status.idle": "2023-03-30T15:48:17.479488Z",
     "shell.execute_reply": "2023-03-30T15:48:17.478399Z",
     "shell.execute_reply.started": "2023-03-30T15:48:17.473131Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(gru_model.parameters(), lr=0.001)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training for 10 epochs with binary cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-30T15:48:20.547766Z",
     "iopub.status.busy": "2023-03-30T15:48:20.547331Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2035/2035 [01:54<00:00, 17.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train loss: 0.15189851038249472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t test loss: 0.08408992221919281, test acc: 0.9739862867497447\n",
      "save model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2035/2035 [01:54<00:00, 17.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, train loss: 0.06922656444864718\n",
      "\t test loss: 0.06623309007196272, test acc: 0.9788696166278918\n",
      "save model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2035/2035 [01:54<00:00, 17.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, train loss: 0.055749132745745944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t test loss: 0.06626128961564516, test acc: 0.9795606538747994\n",
      "save model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2035/2035 [01:54<00:00, 17.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, train loss: 0.04752531959068863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t test loss: 0.059648715245056244, test acc: 0.9810041539016731\n",
      "save model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2035/2035 [01:53<00:00, 17.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, train loss: 0.03670043167646709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t test loss: 0.056870798430312244, test acc: 0.9825628268030313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2035/2035 [01:53<00:00, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, train loss: 0.03296187347709602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t test loss: 0.056324206159060385, test acc: 0.9830004837260728\n",
      "save model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2035/2035 [01:52<00:00, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, train loss: 0.029956169159057796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t test loss: 0.05620339370473546, test acc: 0.9831924385168805\n",
      "save model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2035/2035 [01:54<00:00, 17.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, train loss: 0.027142286673188208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t test loss: 0.05821270885747402, test acc: 0.9831694039419836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2035/2035 [01:53<00:00, 17.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, train loss: 0.025118042731826957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t test loss: 0.06204727367993832, test acc: 0.982201951796313\n"
     ]
    }
   ],
   "source": [
    "best_right = 0\n",
    "early_stop = 0\n",
    "gru_model.to('cuda')\n",
    "for epoch in range(epochs):\n",
    "    loss_value = 0.0\n",
    "    gru_model.train()\n",
    "    for inputs, label in tqdm(trainGenerator):\n",
    "        inputs = inputs.cuda()\n",
    "        label = label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = gru_model(inputs)\n",
    "        l = loss(output, label)\n",
    "        l.backward()\n",
    "        loss_value += l.item()\n",
    "        optimizer.step()\n",
    "    print(f'epoch: {epoch+1}, train loss: {loss_value/len(trainGenerator)}')\n",
    "\n",
    "    # eval\n",
    "    gru_model.cuda()\n",
    "    gru_model.eval()\n",
    "    loss_value = 0.0\n",
    "    right_num = 0\n",
    "    for inputs, label in testGenerator:\n",
    "        inputs = inputs.cuda()\n",
    "        label = label.cuda()\n",
    "        output = gru_model(inputs)\n",
    "        l = loss(output, label)\n",
    "        loss_value += l.item()\n",
    "        right_num += (torch.argmax(output, dim=1) == label).sum().item()\n",
    "    print(f'\\t test loss: {loss_value/len(testGenerator)}, test acc: {right_num/len(testDataset)}')\n",
    "    \n",
    "    # save model or early stop\n",
    "    if right_num > best_right:\n",
    "        best_right = right_num\n",
    "        torch.save(gru_model.state_dict(), './gru_model.pth')\n",
    "        print('save model')\n",
    "        early_stop = 0\n",
    "    else:\n",
    "        early_stop += 1\n",
    "        if early_stop > 3:\n",
    "            print('early stop')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
